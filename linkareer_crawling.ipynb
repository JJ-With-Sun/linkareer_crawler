{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03edb751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "def url_crawl(driver: webdriver.Chrome):\n",
    "    url_list = []\n",
    "    f = open(\"./linkcareer_link.txt\", 'w')\n",
    "    for page in range(1, 42):\n",
    "        url = \"https://linkareer.com/cover-letter/search?keyword=&organizationName=삼성전자&page=\" + str(page) + \"&tab=all\"\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div/div[4]/div/div[2]/div/div[3]/div[1]/div[1]/div[1]/a/div\")\n",
    "            driver.implicitly_wait(3)\n",
    "            url_tag = driver.find_elements(By.TAG_NAME, 'a')\n",
    "            for tag in url_tag:\n",
    "                url_name = tag.get_attribute('href')\n",
    "                if \"cover-letter\" in url_name and \"search\" not in url_name:\n",
    "                    print(url_name)\n",
    "                    url_list.append(url_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during URL crawl: {e}\")\n",
    "            continue\n",
    "    driver.close()\n",
    "    for content in list(set(url_list)):\n",
    "        f.write(content + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "def self_introduction(driver: webdriver.Chrome, url):\n",
    "    person = {}\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    try:\n",
    "        info = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[4]/div/div[2]/div/div[2]/div[1]/div/div/div[2]/h1')\n",
    "        specification = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[4]/div/div[2]/div/div[2]/div[1]/div/div/div[3]/h3')\n",
    "        content = driver.find_element(By.ID, \"coverLetterContent\")\n",
    "        info_list = info.text.split(' /')\n",
    "        person['company'] = info_list[0]\n",
    "        person['job'] = info_list[1]\n",
    "        person['year'] = info_list[2]\n",
    "        person['specification'] = specification.text  # 지원자 스펙\n",
    "        person['self_intro'] = content.text  # 지원자 자소서\n",
    "#         print(person)\n",
    "        return person\n",
    "    except Exception as e:\n",
    "        print(f\"Error during self introduction extraction: {url}, {e}\")\n",
    "        return None  # 에러가 발생하면 None 반환\n",
    "\n",
    "# linkareer_total.py\n",
    "\n",
    "person_list = []\n",
    "url = \"C:\\\\Users\\\\jenni\\\\Documents\\\\아이디어톤\\\\linkcareer_link.txt\"\n",
    "driver = webdriver.Chrome()\n",
    "# url_crawl(driver=driver)\n",
    "with open(url, 'r', encoding='utf-8') as f:\n",
    "    while True:\n",
    "        txt_link = f.readline()\n",
    "        if txt_link == '':\n",
    "            break\n",
    "        person = self_introduction(driver=driver, url=txt_link)\n",
    "        if person is not None:\n",
    "            person_list.append(person)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "df = pd.DataFrame(person_list)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv('./self_introduction.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882434ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
